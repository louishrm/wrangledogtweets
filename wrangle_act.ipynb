{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling WeRateDogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering\n",
    "\n",
    "* **Twitter archive file** Manually download by clicking the link: \n",
    "* **Tweet Image prediction** Programtically download the file \n",
    "* **Tweet JSON file** Get from twitter using API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import requests \n",
    "import tweepy\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Twitter archive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Tweet Image prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "page = requests.get(url)\n",
    "with open('image_predictions.tsv', mode = 'wb') as f: \n",
    "    f.write(page.content)\n",
    "image_prediction = pd.read_csv('image_predictions.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Tweet JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'IlUpuNICtvcgHR66TrBLN43k7'\n",
    "consumer_secret = 'WZXOLRl7sBUpfIBeoukENQ5Z0ZcfPUOB6ouyxSrTYwNcRTXhSs'\n",
    "access_token = '1307275021522530306-jmWn1Fm4mu7i431hpL4gnMsd3dTCfY'\n",
    "access_secret = 'NtlNyDFUgIPFcTxlFDhEPzSeVRAv1vtQLm61dDIBPzFZ5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of the tweet ids from the image_prediction DataFrame. \n",
    "tweet_ids = list(image_prediction['tweet_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we have a Japanese Irish Setter. Lost eye in Vietnam (?). Big fan of relaxing on stair. 8/10 would pet https://t.co/BLDqew2Ijj\n"
     ]
    }
   ],
   "source": [
    "#quick test to check if we can pull tweets correctly. \n",
    "tweet = api.get_status(tweet_ids[0], tweet_mode = 'extended')\n",
    "print(tweet.full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 698\n",
      "Rate limit reached. Sleeping for: 699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process complete, time taken: 1871.3138456344604\n"
     ]
    }
   ],
   "source": [
    "error_log = {}\n",
    "start = time.time()\n",
    "with open('tweet_json.txt', 'w') as outfile: \n",
    "    for index, tweet in image_prediction.iterrows():\n",
    "        try:\n",
    "            tweet_json = api.get_status(tweet.tweet_id, tweet_mode = 'extended')._json\n",
    "            json.dump(tweet_json, outfile)\n",
    "            outfile.write('\\n')\n",
    "        except tweepy.TweepError as e:\n",
    "                error_log[tweet.tweet_id] =e\n",
    "                pass\n",
    "end = time.time()\n",
    "print('process complete, time taken: {}'.format(end-start))\n",
    "\n",
    "with open('error_log.txt', 'w') as filehandle:\n",
    "    for error in error_log:\n",
    "        filehandle.write('%s\\n' % error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_jsons = []\n",
    "jsons_file = open('tweet_json.txt', 'r')\n",
    "for line in jsons_file:\n",
    "    try: \n",
    "        tweet = json.load(line)\n",
    "        tweet_jsons.append(tweet)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "jsons_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tweet_jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programmatic assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main issues\n",
    "\n",
    "#### Quality issues \n",
    "* twitter_archive: source column is in HTML format.\n",
    "* image_prediction: some dog names in p1, p2 and p3 start with capitals and others don't. \n",
    "* \n",
    "* \n",
    "* \n",
    "* \n",
    "* \n",
    "* \n",
    "\n",
    "#### Tidiness issues\n",
    "\n",
    "* twitter_archive : 4 columns for the different dog stages, when only one is necessary.\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, create copies of the DataFrames\n",
    "twitter_archive_clean = twitter_archive.copy()\n",
    "image_prediction_clean = image_prediction.copy()\n",
    "tweet_df_clean = tweet_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*twitter_archive: source column format is in HTML*\n",
    "> Do some string parsing on this column to retain the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean = twitter_archive.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean['source'] = twitter_archive_clean['source'].str.split('\"')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean['source'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*twitter_archive : 4 columns for the different dog stages, when only one is necessary.*\n",
    "> Create a new column dog_stage which melts these 4 stages. Then drop the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_cols = ['doggo', 'floofer', 'pupper', 'puppo']\n",
    "kept_cols = [c for c in list(twitter_archive_clean.columns) if c not in melt_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean = pd.melt(twitter_archive_clean, id_vars = kept_cols, value_vars= melt_cols, var_name = 'stages', value_name ='dog_stage')\n",
    "twitter_archive_clean.drop('stages', axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
